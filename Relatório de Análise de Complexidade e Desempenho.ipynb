{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+CmA5feq7l7AJlR2V9/K4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLNETO22/Algoritmos/blob/main/Relat%C3%B3rio%20de%20An%C3%A1lise%20de%20Complexidade%20e%20Desempenho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Relatório de Análise de Complexidade e Desempenho**"
      ],
      "metadata": {
        "id": "LvdG4WJit30f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Seção 1: Análise de Complexidade Algorítmica (Notação O)**"
      ],
      "metadata": {
        "id": "ati4GN3iuMK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta seção, a complexidade algorítmica da função process_frame no script yolo_detector.py, ignorando a chamada ao model.predict() (ou equivalente, como model(frame)). O foco está nos loops que processam os resultados da detecção, incluindo a contagem de objetos (como pessoas) e o desenho das caixas retangulares (bounding boxes) no frame."
      ],
      "metadata": {
        "id": "LqxqjpDvuTVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A complexidade em Notação O para essa seção de processamento é O(n), onde n representa o número de objetos detectados no frame (ou seja, o número de bounding boxes retornadas nos resultados da detecção)."
      ],
      "metadata": {
        "id": "MBrvSajBz941"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Justificativa:**"
      ],
      "metadata": {
        "id": "6aG3189cubWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Definição de n**: Aqui, n é o número de objetos detectados pelo modelo em um único frame. Isso não depende diretamente do tamanho da imagem (como número de pixels), mas sim da quantidade de instâncias identificadas (por exemplo, pessoas, itens etc.). Em cenários reais, n tende a ser pequeno (ex.: 1 a 20 objetos por frame em uma cena típica de vigilância), mas a análise considera como o tempo escala com o crescimento de n."
      ],
      "metadata": {
        "id": "4BZrSxYSvWDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Explicação da complexidade:**\n",
        "\n",
        "    *   A função process_frame tipicamente inclui um loop externo sobre os resultados (geralmente uma lista com um único item para detecção em imagem única, mas generalizável).\n",
        "    *   Dentro disso, há um loop for principal que itera sobre cada bounding box (ex.: for box in boxes).\n",
        "    *   Para cada box, são realizadas operações de tempo constante: verificação da classe do objeto (ex.: if box.cls == 0 para pessoas), incremento de contadores, e chamadas a funções de desenho do OpenCV como cv2.rectangle e possivelmente cv2.putText (que também são O(1) em relação a n, pois não dependem do número de boxes, mas sim de coordenadas fixas).\n",
        "    *   Não há loops aninhados ou operações que escalem quadraticamente (como comparações entre pairs de boxes). Portanto, o tempo total é proporcional ao número de iterações no loop principal, resultando em O(n). Se n dobrar, o tempo de processamento dessa seção também dobra linearmente."
      ],
      "metadata": {
        "id": "d4839N09vq8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa análise assume que operações como desenho de retângulos são tratadas como constantes, focando na escalabilidade algorítmica em vez do custo absoluto de cada chamada de biblioteca."
      ],
      "metadata": {
        "id": "XxR-xZX8zxIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Seção 2: Identificação do Gargalo Computacional**"
      ],
      "metadata": {
        "id": "eohB8KpBwysQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   **Avaliação do loop de desenho/contagem:** Com base na análise da Seção 1, o loop de processamento (contagem e desenho) é \"barato\" em termos relativos. Sua complexidade O(n), com n tipicamente pequeno, não justifica o baixo FPS observado no programa. Em um frame com poucos objetos (ex.: 5-10), esse loop executa rapidamente, consumindo frações de milissegundos em uma CPU padrão. O baixo desempenho geral (baixo FPS e alta latência) não pode ser atribuído a essa parte, pois ela é eficiente e não escalável de forma problemática para entradas realistas."
      ],
      "metadata": {
        "id": "hUlrT76yyA2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   **Linha ou função responsável pelo gargalo:** O principal gargalo está na chamada à inferência do modelo YOLO, especificamente na linha results = model(frame) (ou equivalente, como model.predict(frame)). Essa é a função que realiza a detecção de objetos usando a rede neural profunda do YOLOv8, e ela consome a vasta maioria do tempo de processamento por frame — frequentemente 80-90% ou mais em ambientes sem aceleração de hardware."
      ],
      "metadata": {
        "id": "C0vvyTkiyJVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.   **Diferença entre Complexidade Algorítmica e Carga Computacional:**"
      ],
      "metadata": {
        "id": "qw4OaTZLyVC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Complexidade Algorítmica (analisada na Seção 1):** Refere-se a como o tempo de execução escala com o tamanho da entrada. No caso do loop de processamento, é O(n), onde n é o número de objetos, significando que o número de operações cresce linearmente. Isso é uma medida assintótica, útil para prever o comportamento em entradas maiores, mas ignora constantes e custos absolutos. Por exemplo, mesmo se n for grande, o loop permanece eficiente se as operações internas forem simples."
      ],
      "metadata": {
        "id": "5_SWGZv_y0TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Carga Computacional Bruta (do gargalo):** Refere-se ao custo absoluto e fixo de uma operação específica, independentemente de escalabilidade. A inferência do YOLO envolve bilhões de operações de ponto flutuante (FLOPs) por chamada — como convoluções, ativações e normalizações em camadas profundas da rede neural. Isso é \"caro\" devido ao volume bruto de computação (ex.: processar uma imagem de 640x480 pode exigir ~10-20 GFLOPs), especialmente em CPU, onde não há paralelismo massivo. Enquanto a complexidade algorítmica da inferência é O(m), onde m é o tamanho da imagem (altura × largura × canais), a carga é o que torna cada chamada lenta na prática, não o scaling per se. Em resumo: a complexidade algorítmica olha para \"como cresce\", enquanto a carga computacional foca no \"quanto custa agora\"."
      ],
      "metadata": {
        "id": "l_OY7fpQ2Uz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Seção 3: Plano de Otimização**"
      ],
      "metadata": {
        "id": "U00QJODt2aCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base no gargalo identificado (a inferência do modelo YOLO), proponho três estratégias para melhorar o FPS e reduzir a latência. Cada uma aborda aspectos diferentes (hardware, software e parâmetros), sem alterar o modelo subjacente, e explica como mitiga o custo computacional da inferência."
      ],
      "metadata": {
        "id": "OBWWcOpR3TSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   **Estratégia de Hardware:** Aceleração via GPU\n",
        "Para acelerar o gargalo, utilize uma GPU dedicada com suporte a CUDA (para NVIDIA) ou equivalente (como TensorRT para otimização). Isso envolve instalar o PyTorch com CUDA habilitado e executar o script em uma máquina com GPU.\n",
        "\n",
        "**O que ela faz e por quê resolve:** A inferência do YOLO é altamente paralelizável, com operações matriciais que se beneficiam do paralelismo massivo das GPUs (milhares de núcleos vs. poucos na CPU). Isso reduz o tempo por frame de segundos para milissegundos, aumentando o FPS de ~1-5 para 30+ em hardware modesto. Mitiga a carga computacional distribuindo os bilhões de FLOPs em paralelo, resolvendo o bottleneck sem mudar o código.\n"
      ],
      "metadata": {
        "id": "gkgCPMdg3WpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   **Estratégia de Design de Software/Algoritmo:** Implementação Assíncrona com Multi-Threading\n",
        "Reestruture o fluxo síncrono do programa usando threads: um thread para captura de frames da webcam (leitura contínua) e outro para inferência e processamento, com uma fila (queue) para buffering de frames. Por exemplo, use threading ou multiprocessing do Python para separar a captura da inferência.\n",
        "\n",
        "**O que ela faz e por quê resolve:** O fluxo síncrono atual bloqueia a captura enquanto espera a inferência lenta, causando latência acumulada e baixo FPS. Com threads, a captura continua em paralelo, reduzindo a percepção de atraso (ex.: frames são processados enquanto novos são lidos). Isso mitiga o gargalo ao sobrepor operações I/O (captura) com computação intensiva, melhorando a responsividade em tempo real sem reduzir a qualidade da detecção."
      ],
      "metadata": {
        "id": "6qUVcpyh3c5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.   **Estratégia de Parâmetros de Entrada:** Redução da Resolução da Imagem\n",
        "Antes de passar o frame ao modelo, redimensione a imagem para uma resolução menor (ex.: de 640x480 para 320x320) usando cv2.resize(frame, (320, 320)), e ajuste parâmetros do modelo como imgsz=320 no YOLO.\n",
        "\n",
        "**O que ela faz e por quê resolve:** O modelo processa imagens menores, reduzindo o número de pixels e, consequentemente, as operações na rede neural (ex.: convoluções escalam quadraticamente com o tamanho). Isso corta a carga computacional em 4x ou mais, aumentando o FPS sem perda significativa de precisão em detecções (YOLO é robusto a resoluções menores). Mitiga o gargalo eliminando entrada excessiva desnecessária para vigilância em tempo real, onde alta resolução não é crítica."
      ],
      "metadata": {
        "id": "mEypvFQt4Hr6"
      }
    }
  ]
}